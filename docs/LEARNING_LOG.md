# Learning Log

This file captures weekly learnings, mistakes, and course corrections.

## Week 0
- Assumed memory = database ❌
- Learned memory = retrieval + context shaping ✅
- Vibe coding is a thing, use it to your advantage but don't get lost in it
- Prompt is not the single line that you write in ChatGPT like applications, it is the entire context that you provide to the LLM
- PII masking techniques can be used to protect sensitive information when sending data to external LLMs
- High latency is observed with locally running LLMs, so need to explore options to optimize it
- Google Antigravity IDE is great for vibe coding   
- Claude is great for coding (Antigravity is supports use of multiple models for coding, so you can use the best model for the task)
- Performant models for realtime conversation are very limited, so need to explore options to optimize it
    - Gemini Flash is a good option for realtime conversation and a free tier is available for development purposes
    - NVIDIA had launched a new model called PersonaPlex 7B, to be explored https://lnkd.in/dffWdxuB
- Claude skills is a great way to abstract the tool information from the LLM
- Next week focus: first crude demo version that reflects the architecture and design decisions made so far

## Week 1
- 



Future entries will be added incrementally.
